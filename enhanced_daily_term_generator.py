#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆæ¯æ—¥åè¯ç”Ÿæˆå™¨
åŒ…å«è´¨é‡è¯„ä¼°ã€æ‰¹é‡ç”Ÿæˆã€ç»Ÿè®¡åˆ†æç­‰é«˜çº§åŠŸèƒ½

ä½¿ç”¨æ–¹æ³•:
python enhanced_daily_term_generator.py
"""

import os
import sys
import json
import random
import requests
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from collections import defaultdict, Counter
import time
import statistics
from pathlib import Path

# å¯¼å…¥é…ç½®
try:
    from config import *
except ImportError:
    print("âŒ æ‰¾ä¸åˆ°config.pyæ–‡ä»¶ï¼Œè¯·ç¡®ä¿é…ç½®æ–‡ä»¶å­˜åœ¨")
    sys.exit(1)

class QualityAnalyzer:
    """è´¨é‡åˆ†æå™¨"""
    
    def __init__(self):
        self.quality_metrics = {
            'content_length': 0,
            'keyword_coverage': 0,
            'readability': 0,
            'completeness': 0,
            'accuracy': 0
        }
    
    def analyze_term(self, term_data: Dict) -> Dict[str, Any]:
        """åˆ†ææœ¯è¯­è´¨é‡"""
        analysis = {
            'overall_score': 0,
            'metrics': {},
            'issues': [],
            'suggestions': []
        }
        
        # å†…å®¹é•¿åº¦åˆ†æ
        analysis['metrics']['content_length'] = self._analyze_content_length(term_data)
        
        # å®Œæ•´æ€§åˆ†æ
        analysis['metrics']['completeness'] = self._analyze_completeness(term_data)
        
        # å…³é”®è¯è¦†ç›–åˆ†æ
        analysis['metrics']['keyword_coverage'] = self._analyze_keyword_coverage(term_data)
        
        # å¯è¯»æ€§åˆ†æ
        analysis['metrics']['readability'] = self._analyze_readability(term_data)
        
        # è®¡ç®—æ€»åˆ†
        scores = list(analysis['metrics'].values())
        analysis['overall_score'] = sum(scores) / len(scores) if scores else 0
        
        # ç”Ÿæˆå»ºè®®
        analysis['suggestions'] = self._generate_suggestions(analysis['metrics'])
        
        return analysis
    
    def _analyze_content_length(self, term_data: Dict) -> float:
        """åˆ†æå†…å®¹é•¿åº¦æ˜¯å¦åˆé€‚"""
        score = 0
        total_checks = 0
        
        # æ£€æŸ¥å®šä¹‰é•¿åº¦
        if 'definition' in term_data:
            def_len = len(term_data['definition'])
            if QUALITY_CONFIG['min_definition_length'] <= def_len <= QUALITY_CONFIG['max_definition_length']:
                score += 1
            total_checks += 1
        
        # æ£€æŸ¥è¯¦ç»†è§£é‡Šé•¿åº¦
        if 'detailed_explanation' in term_data:
            exp_len = len(term_data['detailed_explanation'])
            if QUALITY_CONFIG['min_explanation_length'] <= exp_len <= QUALITY_CONFIG['max_explanation_length']:
                score += 1
            total_checks += 1
        
        return score / total_checks if total_checks > 0 else 0
    
    def _analyze_completeness(self, term_data: Dict) -> float:
        """åˆ†æå†…å®¹å®Œæ•´æ€§"""
        required_fields = [
            'term', 'english_term', 'category', 'difficulty',
            'definition', 'detailed_explanation', 'examples',
            'related_terms', 'learning_tips', 'practical_application'
        ]
        
        present_fields = sum(1 for field in required_fields if field in term_data and term_data[field])
        return present_fields / len(required_fields)
    
    def _analyze_keyword_coverage(self, term_data: Dict) -> float:
        """åˆ†æå…³é”®è¯è¦†ç›–åº¦"""
        if 'category' not in term_data:
            return 0
        
        # æ‰¾åˆ°å¯¹åº”çš„é¢†åŸŸ
        domain_key = None
        for key, domain in CS_DOMAINS.items():
            if domain['name'] == term_data['category']:
                domain_key = key
                break
        
        if not domain_key:
            return 0.5  # é»˜è®¤åˆ†æ•°
        
        keywords = CS_DOMAINS[domain_key]['keywords']
        content = ' '.join([
            term_data.get('definition', ''),
            term_data.get('detailed_explanation', ''),
            ' '.join(term_data.get('examples', [])),
            ' '.join(term_data.get('related_terms', []))
        ]).lower()
        
        matched_keywords = sum(1 for keyword in keywords if keyword.lower() in content)
        return min(matched_keywords / len(keywords) * 2, 1.0)  # æœ€é«˜1.0åˆ†
    
    def _analyze_readability(self, term_data: Dict) -> float:
        """åˆ†æå¯è¯»æ€§ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        score = 0
        checks = 0
        
        # æ£€æŸ¥å®šä¹‰æ˜¯å¦ç®€æ´æ˜äº†
        if 'definition' in term_data:
            definition = term_data['definition']
            # ç®€å•çš„å¯è¯»æ€§æ£€æŸ¥ï¼šå¥å­é•¿åº¦ã€æ ‡ç‚¹ç¬¦å·ç­‰
            sentences = definition.split('ã€‚')
            avg_sentence_length = sum(len(s) for s in sentences) / len(sentences) if sentences else 0
            
            if 10 <= avg_sentence_length <= 50:  # åˆç†çš„å¥å­é•¿åº¦
                score += 1
            checks += 1
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å…·ä½“ä¾‹å­
        if 'examples' in term_data and len(term_data['examples']) >= 2:
            score += 1
        checks += 1
        
        return score / checks if checks > 0 else 0
    
    def _generate_suggestions(self, metrics: Dict) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        suggestions = []
        
        if metrics.get('content_length', 0) < 0.8:
            suggestions.append("å»ºè®®è°ƒæ•´å†…å®¹é•¿åº¦ï¼Œç¡®ä¿å®šä¹‰ç®€æ´ã€è§£é‡Šè¯¦ç»†")
        
        if metrics.get('completeness', 0) < 0.9:
            suggestions.append("å»ºè®®è¡¥å……ç¼ºå¤±çš„å­—æ®µï¼Œç¡®ä¿ä¿¡æ¯å®Œæ•´")
        
        if metrics.get('keyword_coverage', 0) < 0.3:
            suggestions.append("å»ºè®®å¢åŠ ç›¸å…³é¢†åŸŸå…³é”®è¯çš„ä½¿ç”¨")
        
        if metrics.get('readability', 0) < 0.7:
            suggestions.append("å»ºè®®æ”¹å–„å¯è¯»æ€§ï¼Œä½¿ç”¨æ›´æ¸…æ™°çš„è¡¨è¾¾å’Œå…·ä½“ä¾‹å­")
        
        return suggestions

class EnhancedDailyTermGenerator:
    """å¢å¼ºç‰ˆæ¯æ—¥åè¯ç”Ÿæˆå™¨"""
    
    def __init__(self, api_key: str = None):
        self.api_key = api_key or OPENAI_API_KEY
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        self.quality_analyzer = QualityAnalyzer()
        self.generation_history = []
        
        # è®¾ç½®æ—¥å¿—
        self._setup_logging()
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = Path(OUTPUT_CONFIG['save_directory'])
        self.output_dir.mkdir(exist_ok=True)
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logging.basicConfig(
            level=getattr(logging, LOGGING_CONFIG['level']),
            format=LOGGING_CONFIG['format'],
            handlers=[
                logging.FileHandler(LOGGING_CONFIG['file'], encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def select_domain_intelligently(self, exclude_recent: bool = True) -> Tuple[str, str]:
        """æ™ºèƒ½é€‰æ‹©é¢†åŸŸå’Œéš¾åº¦"""
        # æ ¹æ®æƒé‡é€‰æ‹©é¢†åŸŸ
        domains = list(CS_DOMAINS.keys())
        weights = [CS_DOMAINS[d]['weight'] for d in domains]
        
        # å¦‚æœéœ€è¦æ’é™¤æœ€è¿‘ä½¿ç”¨çš„é¢†åŸŸ
        if exclude_recent and len(self.generation_history) > 0:
            recent_domains = [h.get('domain_key') for h in self.generation_history[-3:]]
            for i, domain in enumerate(domains):
                if domain in recent_domains:
                    weights[i] *= 0.3  # é™ä½æœ€è¿‘ä½¿ç”¨è¿‡çš„é¢†åŸŸæƒé‡
        
        # åŠ æƒéšæœºé€‰æ‹©
        domain = random.choices(domains, weights=weights)[0]
        
        # é€‰æ‹©éš¾åº¦
        domain_info = CS_DOMAINS[domain]
        difficulty = random.choice(domain_info['difficulty_levels'])
        
        return domain, difficulty
    
    def generate_term_with_template(self, domain: str, difficulty: str, template: str = "standard") -> Optional[Dict]:
        """ä½¿ç”¨æ¨¡æ¿ç”Ÿæˆæœ¯è¯­"""
        if template not in TERM_GENERATION_TEMPLATES:
            template = "standard"
        
        template_config = TERM_GENERATION_TEMPLATES[template]
        domain_info = CS_DOMAINS[domain]
        
        # æ„å»ºæç¤ºè¯
        date_str = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
        keywords = ', '.join(random.sample(domain_info['keywords'], min(5, len(domain_info['keywords']))))
        
        user_prompt = template_config['user_prompt_template'].format(
            date=date_str,
            category=domain_info['name'],
            difficulty=difficulty,
            keywords=keywords
        )
        
        return self._call_api_with_retry(template_config['system_prompt'], user_prompt)
    
    def _call_api_with_retry(self, system_prompt: str, user_prompt: str) -> Optional[Dict]:
        """å¸¦é‡è¯•çš„APIè°ƒç”¨"""
        for attempt in range(API_CONFIG['max_retries']):
            try:
                payload = {
                    "model": OPENAI_MODEL,
                    "messages": [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    "max_tokens": API_CONFIG['max_tokens'],
                    "temperature": API_CONFIG['temperature'],
                    "top_p": API_CONFIG['top_p']
                }
                
                response = requests.post(
                    OPENAI_API_URL,
                    headers=self.headers,
                    json=payload,
                    timeout=API_CONFIG['timeout']
                )
                
                if response.status_code == 200:
                    result = response.json()
                    content = result['choices'][0]['message']['content']
                    
                    # è§£æJSON
                    try:
                        # æ¸…ç†æ ¼å¼
                        content = content.strip()
                        if content.startswith('```json'):
                            content = content[7:]
                        if content.endswith('```'):
                            content = content[:-3]
                        content = content.strip()
                        
                        parsed_data = json.loads(content)
                        
                        # æ·»åŠ å…ƒæ•°æ®
                        parsed_data['generated_at'] = datetime.now().isoformat()
                        parsed_data['api_model'] = OPENAI_MODEL
                        parsed_data['generation_attempt'] = attempt + 1
                        
                        return parsed_data
                        
                    except json.JSONDecodeError as e:
                        self.logger.warning(f"JSONè§£æå¤±è´¥ (å°è¯• {attempt + 1}): {e}")
                        if attempt == API_CONFIG['max_retries'] - 1:
                            self.logger.error(f"åŸå§‹å†…å®¹: {content[:300]}...")
                        continue
                        
                else:
                    self.logger.warning(f"APIè¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}): {response.status_code}")
                    
            except Exception as e:
                self.logger.warning(f"è¯·æ±‚å¼‚å¸¸ (å°è¯• {attempt + 1}): {e}")
                
            if attempt < API_CONFIG['max_retries'] - 1:
                time.sleep(API_CONFIG['retry_delay'] ** attempt)
                
        return None
    
    def generate_and_analyze(self, domain: str = None, difficulty: str = None, template: str = "standard") -> Optional[Dict]:
        """ç”Ÿæˆå¹¶åˆ†ææœ¯è¯­"""
        # æ™ºèƒ½é€‰æ‹©é¢†åŸŸå’Œéš¾åº¦
        if not domain or not difficulty:
            domain, difficulty = self.select_domain_intelligently()
        
        self.logger.info(f"ç”Ÿæˆæœ¯è¯­: é¢†åŸŸ={CS_DOMAINS[domain]['name']}, éš¾åº¦={difficulty}, æ¨¡æ¿={template}")
        
        # ç”Ÿæˆæœ¯è¯­
        term_data = self.generate_term_with_template(domain, difficulty, template)
        
        if term_data:
            # æ·»åŠ é¢†åŸŸä¿¡æ¯
            term_data['domain_key'] = domain
            
            # è´¨é‡åˆ†æ
            quality_analysis = self.quality_analyzer.analyze_term(term_data)
            term_data['quality_analysis'] = quality_analysis
            
            # è®°å½•åˆ°å†å²
            self.generation_history.append(term_data)
            
            self.logger.info(f"ç”ŸæˆæˆåŠŸ: {term_data.get('term', 'Unknown')} (è´¨é‡åˆ†æ•°: {quality_analysis['overall_score']:.2f})")
            
            return term_data
        else:
            self.logger.error("ç”Ÿæˆå¤±è´¥")
            return None
    
    def batch_generate_with_analysis(self, count: int = 10, min_quality: float = 0.7) -> List[Dict]:
        """æ‰¹é‡ç”Ÿæˆå¹¶ç­›é€‰é«˜è´¨é‡æœ¯è¯­"""
        results = []
        attempts = 0
        max_attempts = count * 3  # æœ€å¤šå°è¯•3å€æ•°é‡
        
        self.logger.info(f"å¼€å§‹æ‰¹é‡ç”Ÿæˆ {count} ä¸ªæœ¯è¯­ï¼Œæœ€ä½è´¨é‡è¦æ±‚: {min_quality}")
        
        while len(results) < count and attempts < max_attempts:
            attempts += 1
            
            # é€‰æ‹©æ¨¡æ¿
            template = random.choice(list(TERM_GENERATION_TEMPLATES.keys()))
            
            term = self.generate_and_analyze(template=template)
            
            if term:
                quality_score = term['quality_analysis']['overall_score']
                
                if quality_score >= min_quality:
                    results.append(term)
                    print(f"âœ… æ¥å—æœ¯è¯­ {len(results)}/{count}: {term.get('term', 'Unknown')} (è´¨é‡: {quality_score:.2f})")
                else:
                    print(f"âŒ æ‹’ç»æœ¯è¯­: {term.get('term', 'Unknown')} (è´¨é‡: {quality_score:.2f} < {min_quality})")
            
            # é¿å…APIé™åˆ¶
            time.sleep(1)
        
        self.logger.info(f"æ‰¹é‡ç”Ÿæˆå®Œæˆ: {len(results)}/{count} ä¸ªæœ¯è¯­é€šè¿‡è´¨é‡æ£€æŸ¥")
        return results
    
    def generate_statistics(self, terms: List[Dict]) -> Dict:
        """ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
        if not terms:
            return {}
        
        stats = {
            'total_count': len(terms),
            'quality_distribution': {},
            'domain_distribution': {},
            'difficulty_distribution': {},
            'average_quality': 0,
            'quality_metrics': {}
        }
        
        # è´¨é‡åˆ†å¸ƒ
        quality_scores = [t['quality_analysis']['overall_score'] for t in terms if 'quality_analysis' in t]
        if quality_scores:
            stats['average_quality'] = statistics.mean(quality_scores)
            stats['quality_distribution'] = {
                'excellent': sum(1 for s in quality_scores if s >= 0.9),
                'good': sum(1 for s in quality_scores if 0.7 <= s < 0.9),
                'fair': sum(1 for s in quality_scores if 0.5 <= s < 0.7),
                'poor': sum(1 for s in quality_scores if s < 0.5)
            }
        
        # é¢†åŸŸåˆ†å¸ƒ
        domains = [t.get('domain_key', 'unknown') for t in terms]
        stats['domain_distribution'] = dict(Counter(domains))
        
        # éš¾åº¦åˆ†å¸ƒ
        difficulties = [t.get('difficulty', 'unknown') for t in terms]
        stats['difficulty_distribution'] = dict(Counter(difficulties))
        
        # è´¨é‡æŒ‡æ ‡å¹³å‡å€¼
        metrics = ['content_length', 'completeness', 'keyword_coverage', 'readability']
        for metric in metrics:
            values = []
            for term in terms:
                if 'quality_analysis' in term and 'metrics' in term['quality_analysis']:
                    if metric in term['quality_analysis']['metrics']:
                        values.append(term['quality_analysis']['metrics'][metric])
            
            if values:
                stats['quality_metrics'][metric] = {
                    'average': statistics.mean(values),
                    'min': min(values),
                    'max': max(values)
                }
        
        return stats
    
    def save_results_with_analysis(self, terms: List[Dict], filename: str = None) -> str:
        """ä¿å­˜ç»“æœå’Œåˆ†æ"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = OUTPUT_CONFIG['filename_format'].format(timestamp=timestamp)
        
        filepath = self.output_dir / filename
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        statistics_data = self.generate_statistics(terms)
        
        # æ„å»ºè¾“å‡ºæ•°æ®
        output_data = {
            'metadata': {
                'generated_at': datetime.now().isoformat(),
                'generator_version': '2.0',
                'total_terms': len(terms),
                'api_model': OPENAI_MODEL
            },
            'statistics': statistics_data,
            'terms': terms
        }
        
        # ä¿å­˜æ–‡ä»¶
        with open(filepath, 'w', encoding='utf-8') as f:
            if OUTPUT_CONFIG['pretty_print']:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
            else:
                json.dump(output_data, f, ensure_ascii=False)
        
        self.logger.info(f"ç»“æœå·²ä¿å­˜åˆ°: {filepath}")
        return str(filepath)

def print_quality_report(term: Dict):
    """æ‰“å°è´¨é‡æŠ¥å‘Š"""
    print(f"\nğŸ“š æœ¯è¯­: {term.get('term', 'N/A')}")
    print(f"ğŸ”¤ è‹±æ–‡: {term.get('english_term', 'N/A')}")
    print(f"ğŸ“‚ åˆ†ç±»: {term.get('category', 'N/A')}")
    print(f"â­ éš¾åº¦: {term.get('difficulty', 'N/A')}")
    
    if 'quality_analysis' in term:
        qa = term['quality_analysis']
        print(f"ğŸ¯ è´¨é‡åˆ†æ•°: {qa['overall_score']:.2f}")
        
        print("ğŸ“Š è´¨é‡æŒ‡æ ‡:")
        for metric, score in qa['metrics'].items():
            print(f"   {metric}: {score:.2f}")
        
        if qa['suggestions']:
            print("ğŸ’¡ æ”¹è¿›å»ºè®®:")
            for suggestion in qa['suggestions']:
                print(f"   â€¢ {suggestion}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¢å¼ºç‰ˆæ¯æ—¥åè¯ç”Ÿæˆå™¨")
    print("=" * 60)
    
    # æ£€æŸ¥APIå¯†é’¥
    if OPENAI_API_KEY == "your-openai-api-key-here":
        print("âŒ è¯·å…ˆè®¾ç½®OpenAI APIå¯†é’¥")
        print("æ–¹æ³•1: è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY")
        print("æ–¹æ³•2: åœ¨config.pyä¸­ä¿®æ”¹ OPENAI_API_KEY")
        return
    
    generator = EnhancedDailyTermGenerator()
    
    while True:
        print("\nğŸ“‹ é€‰æ‹©æ“ä½œ:")
        print("1. æ™ºèƒ½ç”Ÿæˆå•ä¸ªæœ¯è¯­")
        print("2. é«˜è´¨é‡æ‰¹é‡ç”Ÿæˆ")
        print("3. æŒ‡å®šå‚æ•°ç”Ÿæˆ")
        print("4. æŸ¥çœ‹ç”Ÿæˆå†å²")
        print("5. è´¨é‡åˆ†ææŠ¥å‘Š")
        print("6. é¢†åŸŸé…ç½®ä¿¡æ¯")
        print("7. é€€å‡º")
        
        choice = input("\nè¯·é€‰æ‹© (1-7): ").strip()
        
        if choice == "1":
            template = input("é€‰æ‹©æ¨¡æ¿ (standard/beginner_friendly/advanced, é»˜è®¤standard): ").strip()
            if not template:
                template = "standard"
            
            term = generator.generate_and_analyze(template=template)
            if term:
                print_quality_report(term)
                
                save = input("\nğŸ’¾ æ˜¯å¦ä¿å­˜ç»“æœ? (y/n): ").strip().lower()
                if save == 'y':
                    generator.save_results_with_analysis([term])
        
        elif choice == "2":
            count = input("ç”Ÿæˆæ•°é‡ (é»˜è®¤10): ").strip()
            count = int(count) if count.isdigit() else 10
            
            min_quality = input("æœ€ä½è´¨é‡è¦æ±‚ (0.0-1.0, é»˜è®¤0.7): ").strip()
            try:
                min_quality = float(min_quality) if min_quality else 0.7
            except ValueError:
                min_quality = 0.7
            
            print(f"\nğŸ”„ å¼€å§‹æ‰¹é‡ç”Ÿæˆ {count} ä¸ªé«˜è´¨é‡æœ¯è¯­...")
            results = generator.batch_generate_with_analysis(count, min_quality)
            
            if results:
                print(f"\nğŸ“Š ç”Ÿæˆå®Œæˆï¼Œå…± {len(results)} ä¸ªæœ¯è¯­")
                
                # æ˜¾ç¤ºç»Ÿè®¡
                stats = generator.generate_statistics(results)
                print(f"å¹³å‡è´¨é‡åˆ†æ•°: {stats.get('average_quality', 0):.2f}")
                
                filename = generator.save_results_with_analysis(results)
                print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {filename}")
        
        elif choice == "3":
            print("\nğŸ“‚ å¯ç”¨é¢†åŸŸ:")
            for key, info in CS_DOMAINS.items():
                print(f"{key}: {info['name']}")
            
            domain = input("\nè¯·è¾“å…¥é¢†åŸŸé”®å: ").strip()
            if domain not in CS_DOMAINS:
                print("âŒ æ— æ•ˆçš„é¢†åŸŸ")
                continue
            
            difficulty = input(f"è¯·è¾“å…¥éš¾åº¦ {CS_DOMAINS[domain]['difficulty_levels']}: ").strip()
            template = input("é€‰æ‹©æ¨¡æ¿ (standard/beginner_friendly/advanced): ").strip()
            
            if not template:
                template = "standard"
            
            term = generator.generate_and_analyze(domain, difficulty, template)
            if term:
                print_quality_report(term)
        
        elif choice == "4":
            if generator.generation_history:
                print(f"\nğŸ“œ ç”Ÿæˆå†å² (æœ€è¿‘{len(generator.generation_history)}ä¸ª):")
                for i, term in enumerate(generator.generation_history[-10:], 1):
                    quality = term.get('quality_analysis', {}).get('overall_score', 0)
                    print(f"{i}. {term.get('term', 'Unknown')} - è´¨é‡: {quality:.2f}")
            else:
                print("\nğŸ“œ æš‚æ— ç”Ÿæˆå†å²")
        
        elif choice == "5":
            if generator.generation_history:
                stats = generator.generate_statistics(generator.generation_history)
                print("\nğŸ“Š è´¨é‡åˆ†ææŠ¥å‘Š:")
                print(f"æ€»æœ¯è¯­æ•°: {stats['total_count']}")
                print(f"å¹³å‡è´¨é‡: {stats.get('average_quality', 0):.2f}")
                
                if 'quality_distribution' in stats:
                    print("\nè´¨é‡åˆ†å¸ƒ:")
                    for level, count in stats['quality_distribution'].items():
                        print(f"  {level}: {count}")
                
                if 'domain_distribution' in stats:
                    print("\né¢†åŸŸåˆ†å¸ƒ:")
                    for domain, count in stats['domain_distribution'].items():
                        domain_name = CS_DOMAINS.get(domain, {}).get('name', domain)
                        print(f"  {domain_name}: {count}")
            else:
                print("\nğŸ“Š æš‚æ— æ•°æ®å¯åˆ†æ")
        
        elif choice == "6":
            print("\nğŸ“‚ é¢†åŸŸé…ç½®ä¿¡æ¯:")
            for key, info in CS_DOMAINS.items():
                print(f"\nğŸ”¹ {key}: {info['name']}")
                print(f"   æƒé‡: {info['weight']}")
                print(f"   éš¾åº¦çº§åˆ«: {', '.join(info['difficulty_levels'])}")
                print(f"   å…³é”®è¯æ•°é‡: {len(info['keywords'])}")
        
        elif choice == "7":
            print("ğŸ‘‹ å†è§!")
            break
        
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")

if __name__ == "__main__":
    main()
